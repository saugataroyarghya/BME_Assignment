{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OKibmtEDWQ5N",
        "outputId": "3ea935d1-4bd7-4d54-a84d-7d2f9a0536cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "TensorFlow version: 2.19.0\n",
            "\n",
            "============================================================\n",
            "PROTEIN SECONDARY STRUCTURE PREDICTION\n",
            "Using REAL CB513 Dataset from Hugging Face\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PROTEIN 2D STRUCTURE PREDICTION PIPELINE\n",
            "REAL CB513 DATA ONLY - NO SYNTHETIC DATA\n",
            "============================================================\n",
            "\n",
            "1. LOADING REAL CB513 DATASET...\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING CB513 DATASET FROM HUGGING FACE\n",
            "============================================================\n",
            "\n",
            "Downloading CB513.csv from Hugging Face...\n",
            "✓ Download complete!\n",
            "Loading CSV file...\n",
            "✓ Dataset loaded: 511 proteins\n",
            "\n",
            "============================================================\n",
            "PROCESSING REAL CB513 DATA\n",
            "============================================================\n",
            "Columns in dataset: ['input', 'dssp3', 'dssp8', 'disorder', 'cb513_mask']\n",
            "\n",
            "First few rows:\n",
            "                                               input  \\\n",
            "0  RTDCYGNVNRIDTTGASCKTAKPEGLSYCGVSASKKIAERDLQAMD...   \n",
            "1  GKITFYEDRGFQGRHYECSSDHSNLQPYFSRCNSIRVDSGCWMLYE...   \n",
            "2  MFKVYGYDSNIHKCVYCDNAKRLLTVKKQPFEFINIMPEKGVFDDE...   \n",
            "3  APAFSVSPASGASDGQSVSVSVAAAGETYYIAQCAPVGGQDACNPA...   \n",
            "4  TPAFNKPKVELHVHLDGAIKPETILYFGKKRGIALPADTVEELRNI...   \n",
            "\n",
            "                                               dssp3  \\\n",
            "0  CCCCCCCHHHCCCCCECHHHHCCCCCCCCEHHHHHHHHHHCHHHHH...   \n",
            "1  CEEEEEEECCCEEEEEEECCCECCCCCCCCCCCEEEEEECEEEEEC...   \n",
            "2  CEEEEECCCCCCCCHHHHHHHHHHHHCCCCEEEEECCCECCECCHH...   \n",
            "3  CCEEEEECCCCCCCCCEEEEEEECCCCEEEEEEECEECCEECCCCC...   \n",
            "4  CCCCCCCEEEEEEEHHHCCCHHHHHHHHHHHCCCCCCCCHHHHHHH...   \n",
            "\n",
            "                                               dssp8  \\\n",
            "0  CCCTTCCGGGSCCCCBCHHHHTTTTCSCCBHHHHHHHHHHTHHHHH...   \n",
            "1  CEEEEEEETTTEEEEEEECSCBSCCTTTCSCCSEEEEEESEEEEES...   \n",
            "2  CEEEEECCTTTSCCHHHHHHHHHHHHTTCCEEEEESCSBTTBCCHH...   \n",
            "3  CCEEEEECCSSCCSSCEEEEEEESCCSEEEEEEECEETTEECCCTT...   \n",
            "4  CCSCCSCEEEEEEEGGGSCCHHHHHHHHHHHTCCCSCSSHHHHHHH...   \n",
            "\n",
            "                                            disorder  \\\n",
            "0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "1  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "2  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "3  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "4  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....   \n",
            "\n",
            "                                          cb513_mask  \n",
            "0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "1  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "2  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "3  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "4  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1....  \n",
            "\n",
            "Using columns: 'input' for sequences, 'dssp3' for structures\n",
            "\n",
            "Processed 465 valid protein sequences\n",
            "\n",
            "Dataset Statistics:\n",
            "  Total proteins: 465\n",
            "  Average sequence length: 267.8\n",
            "  Helix (H): 33.7%\n",
            "  Sheet (E): 22.6%\n",
            "  Coil (C): 43.8%\n",
            "\n",
            "Sample sequence (first 50 AA): RTDCYGNVNRIDTTGASCKTAKPEGLSYCGVSASKKIAERDLQAMDRYKT\n",
            "Sample structure (first 50 SS): CCCCCCCHHHCCCCCECHHHHCCCCCCCCEHHHHHHHHHHCHHHHHCCHH\n",
            "\n",
            "✓ Using 465 REAL protein sequences from CB513\n",
            "\n",
            "2. PREPROCESSING DATA...\n",
            "  Encoding sequences...\n",
            "  One-hot encoding...\n",
            "  Input shape: (465, 300, 22)\n",
            "  Output shape: (465, 300, 3)\n",
            "\n",
            "3. SPLITTING DATA...\n",
            "  Training set: 297 samples\n",
            "  Validation set: 75 samples\n",
            "  Test set: 93 samples\n",
            "\n",
            "4. CREATING MODEL...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m9,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m41,216\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │            \u001b[38;5;34m99\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193,987\u001b[0m (757.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,987</span> (757.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193,603\u001b[0m (756.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,603</span> (756.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total parameters: 193,987\n",
            "\n",
            "5. TRAINING MODEL ON REAL CB513 DATA...\n",
            "  This will take several minutes...\n",
            "Epoch 1/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.5421 - loss: 0.8911\n",
            "Epoch 1: val_accuracy improved from -inf to 0.61413, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.5450 - loss: 0.8869 - val_accuracy: 0.6141 - val_loss: 0.8106 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.6670 - loss: 0.6988\n",
            "Epoch 2: val_accuracy improved from 0.61413 to 0.62702, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 528ms/step - accuracy: 0.6676 - loss: 0.6981 - val_accuracy: 0.6270 - val_loss: 0.7569 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.7043 - loss: 0.6513\n",
            "Epoch 3: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 526ms/step - accuracy: 0.7045 - loss: 0.6509 - val_accuracy: 0.6093 - val_loss: 0.7432 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7254 - loss: 0.6178\n",
            "Epoch 4: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 527ms/step - accuracy: 0.7256 - loss: 0.6175 - val_accuracy: 0.5936 - val_loss: 0.7563 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.7407 - loss: 0.5910\n",
            "Epoch 5: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 532ms/step - accuracy: 0.7409 - loss: 0.5908 - val_accuracy: 0.5928 - val_loss: 0.7740 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7527 - loss: 0.5726\n",
            "Epoch 6: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 513ms/step - accuracy: 0.7529 - loss: 0.5722 - val_accuracy: 0.5926 - val_loss: 0.7837 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.7641 - loss: 0.5506\n",
            "Epoch 7: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 511ms/step - accuracy: 0.7643 - loss: 0.5503 - val_accuracy: 0.5926 - val_loss: 0.8177 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.7716 - loss: 0.5328\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.7718 - loss: 0.5326 - val_accuracy: 0.5926 - val_loss: 0.8604 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.7763 - loss: 0.5161\n",
            "Epoch 9: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.7765 - loss: 0.5158 - val_accuracy: 0.5927 - val_loss: 0.8541 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.7825 - loss: 0.5089\n",
            "Epoch 10: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.7827 - loss: 0.5085 - val_accuracy: 0.5928 - val_loss: 0.8626 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.7886 - loss: 0.4947\n",
            "Epoch 11: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 510ms/step - accuracy: 0.7888 - loss: 0.4943 - val_accuracy: 0.5928 - val_loss: 0.8791 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.7931 - loss: 0.4843\n",
            "Epoch 12: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 509ms/step - accuracy: 0.7933 - loss: 0.4841 - val_accuracy: 0.5931 - val_loss: 0.8814 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.7987 - loss: 0.4739\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 523ms/step - accuracy: 0.7988 - loss: 0.4738 - val_accuracy: 0.6001 - val_loss: 0.8295 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.7989 - loss: 0.4721\n",
            "Epoch 14: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 523ms/step - accuracy: 0.7990 - loss: 0.4719 - val_accuracy: 0.6181 - val_loss: 0.7814 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 0.8018 - loss: 0.4653\n",
            "Epoch 15: val_accuracy did not improve from 0.62702\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 499ms/step - accuracy: 0.8019 - loss: 0.4652 - val_accuracy: 0.6229 - val_loss: 0.7597 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.8035 - loss: 0.4646\n",
            "Epoch 16: val_accuracy improved from 0.62702 to 0.63093, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.8036 - loss: 0.4644 - val_accuracy: 0.6309 - val_loss: 0.7328 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - accuracy: 0.8046 - loss: 0.4583\n",
            "Epoch 17: val_accuracy improved from 0.63093 to 0.65298, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 481ms/step - accuracy: 0.8047 - loss: 0.4583 - val_accuracy: 0.6530 - val_loss: 0.6988 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - accuracy: 0.8034 - loss: 0.4597\n",
            "Epoch 18: val_accuracy improved from 0.65298 to 0.67840, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.8035 - loss: 0.4596 - val_accuracy: 0.6784 - val_loss: 0.6654 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.8073 - loss: 0.4532\n",
            "Epoch 19: val_accuracy improved from 0.67840 to 0.70004, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.8074 - loss: 0.4532 - val_accuracy: 0.7000 - val_loss: 0.6496 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.8049 - loss: 0.4586\n",
            "Epoch 20: val_accuracy improved from 0.70004 to 0.72076, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.8051 - loss: 0.4583 - val_accuracy: 0.7208 - val_loss: 0.6353 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.8073 - loss: 0.4532\n",
            "Epoch 21: val_accuracy improved from 0.72076 to 0.72622, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 525ms/step - accuracy: 0.8074 - loss: 0.4532 - val_accuracy: 0.7262 - val_loss: 0.6351 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8064 - loss: 0.4586\n",
            "Epoch 22: val_accuracy improved from 0.72622 to 0.72947, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 525ms/step - accuracy: 0.8066 - loss: 0.4583 - val_accuracy: 0.7295 - val_loss: 0.6406 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.8078 - loss: 0.4573\n",
            "Epoch 23: val_accuracy improved from 0.72947 to 0.73427, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 511ms/step - accuracy: 0.8080 - loss: 0.4569 - val_accuracy: 0.7343 - val_loss: 0.6421 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - accuracy: 0.8075 - loss: 0.4563\n",
            "Epoch 24: val_accuracy improved from 0.73427 to 0.73547, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 513ms/step - accuracy: 0.8077 - loss: 0.4559 - val_accuracy: 0.7355 - val_loss: 0.6533 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 0.8098 - loss: 0.4498\n",
            "Epoch 25: val_accuracy improved from 0.73547 to 0.74684, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.8100 - loss: 0.4495 - val_accuracy: 0.7468 - val_loss: 0.6282 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.8136 - loss: 0.4422\n",
            "Epoch 26: val_accuracy improved from 0.74684 to 0.75009, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 515ms/step - accuracy: 0.8138 - loss: 0.4420 - val_accuracy: 0.7501 - val_loss: 0.6341 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.8143 - loss: 0.4381\n",
            "Epoch 27: val_accuracy improved from 0.75009 to 0.75142, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 509ms/step - accuracy: 0.8144 - loss: 0.4380 - val_accuracy: 0.7514 - val_loss: 0.6460 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.8179 - loss: 0.4333\n",
            "Epoch 28: val_accuracy did not improve from 0.75142\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 518ms/step - accuracy: 0.8180 - loss: 0.4331 - val_accuracy: 0.7505 - val_loss: 0.6536 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.8133 - loss: 0.4372\n",
            "Epoch 29: val_accuracy improved from 0.75142 to 0.75658, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 510ms/step - accuracy: 0.8135 - loss: 0.4370 - val_accuracy: 0.7566 - val_loss: 0.6388 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.8173 - loss: 0.4281\n",
            "Epoch 30: val_accuracy improved from 0.75658 to 0.75969, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.8174 - loss: 0.4279 - val_accuracy: 0.7597 - val_loss: 0.6259 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.8187 - loss: 0.4252\n",
            "Epoch 31: val_accuracy improved from 0.75969 to 0.76356, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 524ms/step - accuracy: 0.8188 - loss: 0.4250 - val_accuracy: 0.7636 - val_loss: 0.6201 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.8201 - loss: 0.4246\n",
            "Epoch 32: val_accuracy improved from 0.76356 to 0.76480, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 528ms/step - accuracy: 0.8203 - loss: 0.4243 - val_accuracy: 0.7648 - val_loss: 0.6183 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.8220 - loss: 0.4194\n",
            "Epoch 33: val_accuracy improved from 0.76480 to 0.76729, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.8221 - loss: 0.4192 - val_accuracy: 0.7673 - val_loss: 0.6113 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.8235 - loss: 0.4163\n",
            "Epoch 34: val_accuracy improved from 0.76729 to 0.76729, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.8237 - loss: 0.4160 - val_accuracy: 0.7673 - val_loss: 0.6246 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - accuracy: 0.8240 - loss: 0.4164\n",
            "Epoch 35: val_accuracy improved from 0.76729 to 0.76827, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.8241 - loss: 0.4163 - val_accuracy: 0.7683 - val_loss: 0.6184 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.8237 - loss: 0.4148\n",
            "Epoch 36: val_accuracy improved from 0.76827 to 0.76973, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.8239 - loss: 0.4145 - val_accuracy: 0.7697 - val_loss: 0.6146 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.8244 - loss: 0.4125\n",
            "Epoch 37: val_accuracy did not improve from 0.76973\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.8246 - loss: 0.4122 - val_accuracy: 0.7687 - val_loss: 0.6160 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8254 - loss: 0.4134\n",
            "Epoch 38: val_accuracy improved from 0.76973 to 0.77040, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 525ms/step - accuracy: 0.8256 - loss: 0.4131 - val_accuracy: 0.7704 - val_loss: 0.6112 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.8271 - loss: 0.4054\n",
            "Epoch 39: val_accuracy improved from 0.77040 to 0.77049, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 502ms/step - accuracy: 0.8273 - loss: 0.4052 - val_accuracy: 0.7705 - val_loss: 0.6111 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.8260 - loss: 0.4072\n",
            "Epoch 40: val_accuracy did not improve from 0.77049\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 516ms/step - accuracy: 0.8262 - loss: 0.4070 - val_accuracy: 0.7679 - val_loss: 0.6199 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.8271 - loss: 0.4076\n",
            "Epoch 41: val_accuracy did not improve from 0.77049\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 519ms/step - accuracy: 0.8273 - loss: 0.4073 - val_accuracy: 0.7697 - val_loss: 0.6157 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - accuracy: 0.8262 - loss: 0.4042\n",
            "Epoch 42: val_accuracy did not improve from 0.77049\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.8264 - loss: 0.4039 - val_accuracy: 0.7702 - val_loss: 0.6112 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.8327 - loss: 0.3970\n",
            "Epoch 43: val_accuracy improved from 0.77049 to 0.77156, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.8328 - loss: 0.3969 - val_accuracy: 0.7716 - val_loss: 0.6082 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.8305 - loss: 0.3992\n",
            "Epoch 44: val_accuracy did not improve from 0.77156\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.8307 - loss: 0.3989 - val_accuracy: 0.7713 - val_loss: 0.6187 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - accuracy: 0.8317 - loss: 0.3938\n",
            "Epoch 45: val_accuracy improved from 0.77156 to 0.77196, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.8318 - loss: 0.3937 - val_accuracy: 0.7720 - val_loss: 0.6214 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.8344 - loss: 0.3939\n",
            "Epoch 46: val_accuracy did not improve from 0.77196\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.8345 - loss: 0.3938 - val_accuracy: 0.7719 - val_loss: 0.6166 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8356 - loss: 0.3918\n",
            "Epoch 47: val_accuracy did not improve from 0.77196\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 514ms/step - accuracy: 0.8356 - loss: 0.3917 - val_accuracy: 0.7714 - val_loss: 0.6189 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.8366 - loss: 0.3861\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.77196\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.8368 - loss: 0.3859 - val_accuracy: 0.7709 - val_loss: 0.6179 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.8367 - loss: 0.3886\n",
            "Epoch 49: val_accuracy improved from 0.77196 to 0.77382, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 537ms/step - accuracy: 0.8369 - loss: 0.3884 - val_accuracy: 0.7738 - val_loss: 0.6093 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8375 - loss: 0.3884\n",
            "Epoch 50: val_accuracy improved from 0.77382 to 0.77391, saving model to best_model.keras\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 533ms/step - accuracy: 0.8376 - loss: 0.3882 - val_accuracy: 0.7739 - val_loss: 0.6042 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 50.\n",
            "\n",
            "6. CREATING WEIGHT EVOLUTION GIFS...\n",
            "  ✓ GIF saved: gifs/conv1_weights.gif\n",
            "\n",
            "7. EVALUATING MODEL ON TEST SET...\n",
            "  Loading best model...\n",
            "  Making predictions...\n"
          ]
        }
      ],
      "source": [
        "# Protein 2D Structure Prediction Using REAL CB513 Dataset from Hugging Face\n",
        "# NO SYNTHETIC DATA - ONLY REAL PROTEINS\n",
        "\n",
        "# ============================================\n",
        "# PART 1: INSTALLATION AND IMPORTS\n",
        "# ============================================\n",
        "\n",
        "!pip install matplotlib seaborn scikit-learn imageio pillow\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import urllib.request\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROTEIN SECONDARY STRUCTURE PREDICTION\")\n",
        "print(\"Using REAL CB513 Dataset from Hugging Face\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================\n",
        "# PART 2: DOWNLOAD AND LOAD CB513 FROM HUGGING FACE\n",
        "# ============================================\n",
        "\n",
        "def download_cb513_from_huggingface():\n",
        "    \"\"\"Download CB513 dataset from Hugging Face\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DOWNLOADING CB513 DATASET FROM HUGGING FACE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create data directory\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "\n",
        "    # Download CB513.csv from Hugging Face\n",
        "    url = \"https://huggingface.co/datasets/proteinea/secondary_structure_prediction/resolve/main/CB513.csv\"\n",
        "    filepath = \"data/CB513.csv\"\n",
        "\n",
        "    try:\n",
        "        print(\"\\nDownloading CB513.csv from Hugging Face...\")\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "        print(\"✓ Download complete!\")\n",
        "\n",
        "        # Load the CSV file\n",
        "        print(\"Loading CSV file...\")\n",
        "        data = pd.read_csv(filepath)\n",
        "        print(f\"✓ Dataset loaded: {data.shape[0]} proteins\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Download failed: {str(e)}\")\n",
        "        print(\"\\nPlease manually download from:\")\n",
        "        print(\"https://huggingface.co/datasets/proteinea/secondary_structure_prediction/blob/main/CB513.csv\")\n",
        "        return None\n",
        "\n",
        "def process_cb513_csv(df):\n",
        "    \"\"\"Process CB513 CSV data into sequences and structures\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PROCESSING REAL CB513 DATA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    sequences = []\n",
        "    structures = []\n",
        "\n",
        "    # Check the structure of the dataframe\n",
        "    print(f\"Columns in dataset: {df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Based on the output, we have:\n",
        "    # 'input' - protein sequences\n",
        "    # 'dssp3' - 3-class secondary structure\n",
        "    # 'dssp8' - 8-class secondary structure\n",
        "\n",
        "    seq_col = 'input'\n",
        "    struct_col = 'dssp3'  # Using 3-class directly\n",
        "\n",
        "    print(f\"\\nUsing columns: '{seq_col}' for sequences, '{struct_col}' for structures\")\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        seq = str(row[seq_col]).upper().strip()\n",
        "        struct = str(row[struct_col]).upper().strip()\n",
        "\n",
        "        # Clean sequences - keep only valid amino acids\n",
        "        seq = ''.join([aa for aa in seq if aa in 'ACDEFGHIKLMNPQRSTVWY'])\n",
        "\n",
        "        # Ensure structure has only H, E, C\n",
        "        struct = ''.join([ss if ss in 'HEC' else 'C' for ss in struct])\n",
        "\n",
        "        # Only add if lengths match and are reasonable\n",
        "        if len(seq) == len(struct) and 30 < len(seq) < 700:\n",
        "            sequences.append(seq)\n",
        "            structures.append(struct)\n",
        "\n",
        "    print(f\"\\nProcessed {len(sequences)} valid protein sequences\")\n",
        "\n",
        "    if len(sequences) > 0:\n",
        "        # Show statistics\n",
        "        avg_len = np.mean([len(s) for s in sequences])\n",
        "        all_ss = ''.join(structures)\n",
        "        h_pct = 100 * all_ss.count('H') / len(all_ss)\n",
        "        e_pct = 100 * all_ss.count('E') / len(all_ss)\n",
        "        c_pct = 100 * all_ss.count('C') / len(all_ss)\n",
        "\n",
        "        print(f\"\\nDataset Statistics:\")\n",
        "        print(f\"  Total proteins: {len(sequences)}\")\n",
        "        print(f\"  Average sequence length: {avg_len:.1f}\")\n",
        "        print(f\"  Helix (H): {h_pct:.1f}%\")\n",
        "        print(f\"  Sheet (E): {e_pct:.1f}%\")\n",
        "        print(f\"  Coil (C): {c_pct:.1f}%\")\n",
        "\n",
        "        print(f\"\\nSample sequence (first 50 AA): {sequences[0][:50]}\")\n",
        "        print(f\"Sample structure (first 50 SS): {structures[0][:50]}\")\n",
        "\n",
        "    return sequences, structures\n",
        "\n",
        "# ============================================\n",
        "# PART 3: DATA PREPROCESSING\n",
        "# ============================================\n",
        "\n",
        "class ProteinDataProcessor:\n",
        "    def __init__(self, max_len=200):\n",
        "        self.max_len = max_len\n",
        "        self.amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "        self.ss_classes = 'HEC'  # Helix, Sheet (Extended), Coil\n",
        "\n",
        "        # Create mapping dictionaries\n",
        "        self.aa_to_idx = {aa: idx+1 for idx, aa in enumerate(self.amino_acids)}\n",
        "        self.aa_to_idx['PAD'] = 0\n",
        "        self.aa_to_idx['UNK'] = len(self.amino_acids) + 1\n",
        "\n",
        "        self.ss_to_idx = {ss: idx for idx, ss in enumerate(self.ss_classes)}\n",
        "        self.idx_to_ss = {idx: ss for ss, idx in self.ss_to_idx.items()}\n",
        "\n",
        "    def encode_sequence(self, sequence):\n",
        "        \"\"\"Convert amino acid sequence to indices\"\"\"\n",
        "        encoded = []\n",
        "        for aa in sequence[:self.max_len]:\n",
        "            encoded.append(self.aa_to_idx.get(aa, self.aa_to_idx['UNK']))\n",
        "\n",
        "        # Pad sequence\n",
        "        while len(encoded) < self.max_len:\n",
        "            encoded.append(self.aa_to_idx['PAD'])\n",
        "\n",
        "        return np.array(encoded)\n",
        "\n",
        "    def encode_structure(self, structure):\n",
        "        \"\"\"Convert secondary structure to indices\"\"\"\n",
        "        encoded = []\n",
        "        for ss in structure[:self.max_len]:\n",
        "            if ss in self.ss_to_idx:\n",
        "                encoded.append(self.ss_to_idx[ss])\n",
        "            else:\n",
        "                encoded.append(2)  # Default to coil (C)\n",
        "\n",
        "        # Pad structure\n",
        "        while len(encoded) < self.max_len:\n",
        "            encoded.append(2)  # Pad with coil\n",
        "\n",
        "        return np.array(encoded)\n",
        "\n",
        "    def one_hot_encode_sequence(self, encoded_seq):\n",
        "        \"\"\"One-hot encode the sequence\"\"\"\n",
        "        return to_categorical(encoded_seq, num_classes=len(self.aa_to_idx))\n",
        "\n",
        "    def one_hot_encode_structure(self, encoded_struct):\n",
        "        \"\"\"One-hot encode the structure\"\"\"\n",
        "        return to_categorical(encoded_struct, num_classes=len(self.ss_classes))\n",
        "\n",
        "# ============================================\n",
        "# PART 4: MODEL ARCHITECTURE\n",
        "# ============================================\n",
        "\n",
        "def create_protein_model(input_shape, num_classes=3):\n",
        "    \"\"\"Create a hybrid CNN-LSTM model for protein structure prediction\"\"\"\n",
        "    model = models.Sequential([\n",
        "        # Input layer\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        # CNN layers for local pattern detection\n",
        "        layers.Conv1D(64, 7, padding='same', activation='relu', name='conv1'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv1D(128, 5, padding='same', activation='relu', name='conv2'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        # Bidirectional LSTM for sequence context\n",
        "        layers.Bidirectional(layers.LSTM(64, return_sequences=True, name='lstm1')),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Bidirectional(layers.LSTM(32, return_sequences=True, name='lstm2')),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # Dense layers for classification\n",
        "        layers.TimeDistributed(layers.Dense(32, activation='relu', name='dense1')),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        # Output layer\n",
        "        layers.TimeDistributed(layers.Dense(num_classes, activation='softmax', name='output'))\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# ============================================\n",
        "# PART 5: WEIGHT TRACKING FOR GIFS\n",
        "# ============================================\n",
        "\n",
        "class WeightTracker(callbacks.Callback):\n",
        "    def __init__(self, layer_names):\n",
        "        self.layer_names = layer_names\n",
        "        self.weights_history = {name: [] for name in layer_names}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for layer in self.model.layers:\n",
        "            if layer.name in self.layer_names:\n",
        "                weights = layer.get_weights()\n",
        "                if len(weights) > 0:\n",
        "                    self.weights_history[layer.name].append(weights[0].copy())\n",
        "\n",
        "def create_weight_gif(weights_history, layer_name, output_path):\n",
        "    \"\"\"Create GIF showing weight evolution\"\"\"\n",
        "    images = []\n",
        "\n",
        "    for epoch, weights in enumerate(weights_history):\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "        # Reshape weights for visualization\n",
        "        if len(weights.shape) == 3:  # Conv1D weights\n",
        "            weights_2d = weights.reshape(-1, weights.shape[-1])\n",
        "        elif len(weights.shape) == 2:  # Dense weights\n",
        "            weights_2d = weights\n",
        "        else:\n",
        "            weights_2d = weights.reshape(-1, weights.shape[-1] if len(weights.shape) > 1 else 1)\n",
        "\n",
        "        # Limit display size\n",
        "        display_weights = weights_2d[:min(50, weights_2d.shape[0]), :min(50, weights_2d.shape[1])]\n",
        "\n",
        "        im = ax.imshow(display_weights, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "        ax.set_title(f'{layer_name} Weights - Epoch {epoch+1}', fontsize=14)\n",
        "        ax.set_xlabel('Output Units')\n",
        "        ax.set_ylabel('Input Units')\n",
        "        plt.colorbar(im, ax=ax)\n",
        "\n",
        "        # Save to temporary file\n",
        "        temp_path = f'temp_{epoch}.png'\n",
        "        plt.savefig(temp_path, dpi=60, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Load and append to images\n",
        "        images.append(Image.open(temp_path))\n",
        "        os.remove(temp_path)\n",
        "\n",
        "    # Save as GIF\n",
        "    if images:\n",
        "        images[0].save(output_path, save_all=True, append_images=images[1:],\n",
        "                      duration=200, loop=0)\n",
        "        print(f\"  ✓ GIF saved: {output_path}\")\n",
        "\n",
        "# ============================================\n",
        "# PART 6: VISUALIZATION FUNCTIONS\n",
        "# ============================================\n",
        "\n",
        "def create_all_plots(history, y_true, y_pred):\n",
        "    \"\"\"Create all required visualization plots\"\"\"\n",
        "\n",
        "    # 1. Loss and Accuracy Curves\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Loss plot\n",
        "    axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2, color='blue')\n",
        "    axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
        "    axes[0].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy plot\n",
        "    axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, color='blue')\n",
        "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='red')\n",
        "    axes[1].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[1].legend(loc='lower right')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_curves.png', dpi=100, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Helix', 'Sheet', 'Coil'],\n",
        "                yticklabels=['Helix', 'Sheet', 'Coil'],\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicted', fontsize=12)\n",
        "    plt.ylabel('Actual', fontsize=12)\n",
        "    plt.savefig('confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def save_model_architecture(model):\n",
        "    \"\"\"Save model architecture diagram\"\"\"\n",
        "    try:\n",
        "        tf.keras.utils.plot_model(\n",
        "            model,\n",
        "            to_file='model_architecture.png',\n",
        "            show_shapes=True,\n",
        "            show_layer_names=True,\n",
        "            rankdir='TB',\n",
        "            expand_nested=True,\n",
        "            dpi=96\n",
        "        )\n",
        "        print(\"✓ Model architecture saved as 'model_architecture.png'\")\n",
        "    except:\n",
        "        print(\"⚠ Could not generate model architecture diagram\")\n",
        "        print(\"  To fix: !apt-get install graphviz && !pip install pydot\")\n",
        "\n",
        "# ============================================\n",
        "# PART 7: MAIN TRAINING PIPELINE\n",
        "# ============================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PROTEIN 2D STRUCTURE PREDICTION PIPELINE\")\n",
        "    print(\"REAL CB513 DATA ONLY - NO SYNTHETIC DATA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Step 1: Download and Load CB513 Data\n",
        "    print(\"\\n1. LOADING REAL CB513 DATASET...\")\n",
        "    cb513_df = download_cb513_from_huggingface()\n",
        "\n",
        "    if cb513_df is None:\n",
        "        print(\"\\nError: Could not load CB513 dataset!\")\n",
        "        return None, None, 0\n",
        "\n",
        "    # Process CB513 data\n",
        "    sequences, structures = process_cb513_csv(cb513_df)\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        print(\"\\nError: No valid sequences found in CB513!\")\n",
        "        return None, None, 0\n",
        "\n",
        "    print(f\"\\n✓ Using {len(sequences)} REAL protein sequences from CB513\")\n",
        "\n",
        "    # Step 2: Preprocess Data\n",
        "    print(\"\\n2. PREPROCESSING DATA...\")\n",
        "    processor = ProteinDataProcessor(max_len=300)  # Increased to handle longer sequences\n",
        "\n",
        "    # Encode sequences and structures\n",
        "    print(\"  Encoding sequences...\")\n",
        "    X_encoded = np.array([processor.encode_sequence(seq) for seq in sequences])\n",
        "    y_encoded = np.array([processor.encode_structure(struct) for struct in structures])\n",
        "\n",
        "    # One-hot encode\n",
        "    print(\"  One-hot encoding...\")\n",
        "    X = np.array([processor.one_hot_encode_sequence(x) for x in X_encoded])\n",
        "    y = np.array([processor.one_hot_encode_structure(y) for y in y_encoded])\n",
        "\n",
        "    print(f\"  Input shape: {X.shape}\")\n",
        "    print(f\"  Output shape: {y.shape}\")\n",
        "\n",
        "    # Step 3: Split Data\n",
        "    print(\"\\n3. SPLITTING DATA...\")\n",
        "    # Since CB513 is traditionally a test set, we'll split it for training/validation/test\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"  Training set: {X_train.shape[0]} samples\")\n",
        "    print(f\"  Validation set: {X_val.shape[0]} samples\")\n",
        "    print(f\"  Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "    # Step 4: Create Model\n",
        "    print(\"\\n4. CREATING MODEL...\")\n",
        "    model = create_protein_model(\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        num_classes=3\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\nModel Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Calculate total parameters\n",
        "    total_params = model.count_params()\n",
        "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "\n",
        "    # Step 5: Train Model\n",
        "    print(\"\\n5. TRAINING MODEL ON REAL CB513 DATA...\")\n",
        "    print(\"  This will take several minutes...\")\n",
        "\n",
        "    # Callbacks\n",
        "    tracked_layers = ['conv1', 'lstm1', 'dense1']\n",
        "    weight_tracker = WeightTracker(tracked_layers)\n",
        "\n",
        "    early_stop = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=0.00001,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Model checkpoint\n",
        "    checkpoint = callbacks.ModelCheckpoint(\n",
        "        'best_model.keras',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,  # More epochs since we have less data\n",
        "        batch_size=16,  # Smaller batch size for small dataset\n",
        "        callbacks=[weight_tracker, early_stop, reduce_lr, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Step 6: Create Weight GIFs\n",
        "    print(\"\\n6. CREATING WEIGHT EVOLUTION GIFS...\")\n",
        "    os.makedirs('gifs', exist_ok=True)\n",
        "\n",
        "    for layer_name in tracked_layers:\n",
        "        if layer_name in weight_tracker.weights_history:\n",
        "            weights = weight_tracker.weights_history[layer_name]\n",
        "            if weights:\n",
        "                create_weight_gif(weights, layer_name, f'gifs/{layer_name}_weights.gif')\n",
        "\n",
        "    # Step 7: Evaluation\n",
        "    print(\"\\n7. EVALUATING MODEL ON TEST SET...\")\n",
        "\n",
        "    # Load best model\n",
        "    if os.path.exists('best_model.keras'):\n",
        "        print(\"  Loading best model...\")\n",
        "        model = keras.models.load_model('best_model.keras')\n",
        "\n",
        "    # Predictions on test set\n",
        "    print(\"  Making predictions...\")\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=-1).flatten()\n",
        "    y_true_classes = np.argmax(y_test, axis=-1).flatten()\n",
        "\n",
        "    # Remove padding from evaluation\n",
        "    mask = X_test.sum(axis=-1).flatten() > 0\n",
        "    y_pred_filtered = y_pred_classes[mask]\n",
        "    y_true_filtered = y_true_classes[mask]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true_filtered, y_pred_filtered)\n",
        "    report = classification_report(\n",
        "        y_true_filtered, y_pred_filtered,\n",
        "        target_names=['Helix', 'Sheet', 'Coil'],\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  Test Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\n  Classification Report:\")\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    print(report_df.round(3))\n",
        "\n",
        "    # Calculate per-position accuracy\n",
        "    print(\"\\n  Per-Position Statistics:\")\n",
        "    total_positions = len(y_true_filtered)\n",
        "    helix_correct = np.sum((y_true_filtered == 0) & (y_pred_filtered == 0))\n",
        "    sheet_correct = np.sum((y_true_filtered == 1) & (y_pred_filtered == 1))\n",
        "    coil_correct = np.sum((y_true_filtered == 2) & (y_pred_filtered == 2))\n",
        "\n",
        "    print(f\"    Total amino acids evaluated: {total_positions}\")\n",
        "    print(f\"    Helix predictions correct: {helix_correct}\")\n",
        "    print(f\"    Sheet predictions correct: {sheet_correct}\")\n",
        "    print(f\"    Coil predictions correct: {coil_correct}\")\n",
        "\n",
        "    # Step 8: Visualizations\n",
        "    print(\"\\n8. CREATING VISUALIZATIONS...\")\n",
        "    create_all_plots(history, y_true_filtered, y_pred_filtered)\n",
        "\n",
        "    # Step 9: Save Model Architecture\n",
        "    print(\"\\n9. SAVING MODEL ARCHITECTURE...\")\n",
        "    save_model_architecture(model)\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING COMPLETE - REAL CB513 DATA\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(\"  ✓ gifs/conv1_weights.gif - Conv layer weight evolution\")\n",
        "    print(\"  ✓ gifs/lstm1_weights.gif - LSTM layer weight evolution\")\n",
        "    print(\"  ✓ gifs/dense1_weights.gif - Dense layer weight evolution\")\n",
        "    print(\"  ✓ training_curves.png - Loss and accuracy plots\")\n",
        "    print(\"  ✓ confusion_matrix.png - Test set confusion matrix\")\n",
        "    print(\"  ✓ model_architecture.png - Network architecture diagram\")\n",
        "    print(\"  ✓ protein_2d_model.h5 - Trained model\")\n",
        "    print(\"  ✓ best_model.keras - Best checkpoint\")\n",
        "    print(\"  ✓ training_history.json - Training metrics\")\n",
        "\n",
        "    return model, history, accuracy\n",
        "\n",
        "# ============================================\n",
        "# PART 8: RUN THE COMPLETE PIPELINE\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the complete pipeline\n",
        "    model, history, test_accuracy = main()\n",
        "\n",
        "    # Save the model and history\n",
        "    if model is not None:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SAVING FINAL OUTPUTS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Save model in H5 format\n",
        "        model.save('protein_2d_model.h5')\n",
        "        print(\"✓ Model saved as 'protein_2d_model.h5'\")\n",
        "\n",
        "        # Save training history\n",
        "        with open('training_history.json', 'w') as f:\n",
        "            json.dump(history.history, f, indent=2)\n",
        "        print(\"✓ Training history saved as 'training_history.json'\")\n",
        "\n",
        "        # Create summary statistics\n",
        "        stats = {\n",
        "            'dataset': 'CB513 from Hugging Face',\n",
        "            'total_proteins': len(history.history['loss']) * 16,  # epochs * batch_size approximation\n",
        "            'test_accuracy': float(test_accuracy),\n",
        "            'model_parameters': int(model.count_params()),\n",
        "            'epochs_trained': len(history.history['loss'])\n",
        "        }\n",
        "\n",
        "        with open('training_stats.json', 'w') as f:\n",
        "            json.dump(stats, f, indent=2)\n",
        "        print(\"✓ Training statistics saved as 'training_stats.json'\")\n",
        "\n",
        "        # Create final report\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ASSIGNMENT COMPLETE!\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
        "        print(\"\\nDataset: REAL CB513 proteins from Hugging Face\")\n",
        "        print(\"No synthetic data was used - only real protein structures\")\n",
        "        print(\"\\nYou can now:\")\n",
        "        print(\"1. Upload all generated files to GitHub\")\n",
        "        print(\"2. Complete your report with the actual metrics\")\n",
        "        print(\"3. Include the visualizations in your submission\")\n",
        "        print(\"\\nGood luck with your assignment!\")\n",
        "    else:\n",
        "        print(\"\\nError: Training failed. Please check the error messages above.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MqwBIzTvZ6Lc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}